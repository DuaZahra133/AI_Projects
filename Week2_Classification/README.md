# Week 2 â€“ Classification Mastery

This folder contains all **Week 2 Classification projects** from my AI/ML learning roadmap.  
The focus of Week 2 is to **master classification techniques**, including **Logistic Regression, Decision Trees, Random Forest, KNN, and SVM**, along with **model evaluation, visualization, and hyperparameter tuning**.  


---

## ðŸ“‚ Projects Overview

### **1. Project 1 â€“ Logistic Regression: Titanic Survival Prediction**
- **Objective:** Predict passenger survival on the Titanic using logistic regression.  
- **Techniques:** Logistic Regression, Train/Test Split, Evaluation Metrics (Accuracy, ROC, Precision, Recall)  
- **Dataset:** Titanic dataset (passenger demographics and survival status)  
- **Outcome:** Built a predictive model and interpreted key features influencing survival.  
- **Notebook:** `01_LogisticRegression_Titanic.ipynb`

---

### **2. Project 2 â€“ Decision Tree: Student Pass/Fail Prediction**
- **Objective:** Predict student pass/fail outcomes using decision trees.  
- **Techniques:** Decision Tree Classifier, Feature Importance, Model Visualization  
- **Dataset:** Student performance dataset  
- **Outcome:** Generated decision rules and visualizations to explain predictions.  
- **Notebook:** `02_DecisionTree_StudentPassFail.ipynb`

---

### **3. Project 3 â€“ Random Forest: Advanced Classification**
- **Objective:** Improve classification performance using ensemble methods.  
- **Techniques:** Random Forest Classifier, Feature Importance, Cross-Validation  
- **Dataset:** Student performance dataset  
- **Outcome:** Achieved higher accuracy and identified key features for prediction.  
- **Notebook:** `03_RandomForest_StudentPassFail.ipynb`

---

### **4. Project 4 â€“ KNN & SVM Classification**
- **Objective:** Compare performance of K-Nearest Neighbors and Support Vector Machine classifiers.  
- **Techniques:** KNN, SVM, Accuracy & Confusion Matrix Comparison, Hyperparameter Tuning  
- **Dataset:** Student dataset for classification  
- **Outcome:** Evaluated strengths and weaknesses of each algorithm; selected the best model.  
- **Notebook:** `04_KNN_SVM_Classification.ipynb`

---

### **5. Project 5 â€“ Mini Project: End-to-End Classification**
- **Objective:** Apply all classification techniques in a single end-to-end project.  
- **Techniques:**  
  - Exploratory Data Analysis (EDA)  
  - Preprocessing & Feature Engineering  
  - Model Training: Logistic Regression, Decision Tree, Random Forest, KNN, SVM  
  - Model Evaluation: Accuracy, Precision, Recall, ROC Curve  
  - Visualization & Insights  
- **Dataset:** Combined student performance dataset  
- **Outcome:** Portfolio-ready project demonstrating complete classification workflow.  
- **Notebook:** `05_Classification_MiniProject.ipynb`

---

## ðŸ“Š Key Skills Learned
- Logistic Regression and Classification algorithms  
- Decision Trees and Random Forest for ensemble learning  
- K-Nearest Neighbors and Support Vector Machine modeling  
- Hyperparameter tuning and model comparison  
- Model evaluation: Accuracy, Precision, Recall, F1 Score, ROC Curve  

---

## âš¡ How to Use
1. Clone or download the folder.  
2. Open notebooks in **Google Colab** or **Jupyter Notebook**.  
3. Follow the workflow in each notebook:  
