# Week 2 â€“ Classification Mastery

This folder contains all **Week 2 Classification projects** from my AI/ML roadmap.  
The focus of Week 2 is to **master classification algorithms**, including **Logistic Regression, Decision Trees, Random Forest, K-Nearest Neighbors, and Support Vector Machines**, along with **hyperparameter tuning, model evaluation, and visualization**.  


---

## ðŸ“‚ Projects Overview

### **1. Day 31 â€“ Logistic Regression: Titanic Dataset**
- **Objective:** Predict passenger survival on the Titanic using logistic regression.  
- **Techniques:** Logistic Regression, Train/Test Split, Evaluation Metrics (Accuracy, Precision, Recall, ROC)  
- **Dataset:** Titanic dataset (passenger demographics and survival status)  
- **Outcome:** Built a predictive model and interpreted the most important features influencing survival.  
- **Notebook:** `Day31_LogisticRegression_Titanic.ipynb`

---

### **2. Day 32 â€“ Decision Tree & Random Forest**
- **Objective:** Predict student pass/fail outcomes using Decision Tree and Random Forest classifiers.  
- **Techniques:** Decision Tree Classifier, Random Forest Classifier, Feature Importance, Model Visualization  
- **Dataset:** Student performance dataset  
- **Outcome:** Generated decision rules, visualized trees, and improved prediction accuracy using ensemble methods.  
- **Notebook:** `Day32_Classification_DT_RF.ipynb`

---

### **3. Day 33 â€“ KNN & SVM: Student Pass/Fail Prediction**
- **Objective:** Compare K-Nearest Neighbors and Support Vector Machine classifiers for student pass/fail prediction.  
- **Techniques:** KNN, SVM, Model Evaluation (Accuracy, Confusion Matrix), Comparison of Classifiers  
- **Dataset:** Student performance dataset  
- **Outcome:** Evaluated strengths and weaknesses of KNN and SVM; selected the best performing model.  
- **Notebook:** `Day33_KNN_SVM_StudentPassFail.ipynb`

---

### **4. Day 35 â€“ Hyperparameter Tuning & Classifier Comparison**
- **Objective:** Optimize model performance and compare multiple classification algorithms.  
- **Techniques:** GridSearchCV, RandomizedSearchCV, Cross-Validation, Evaluation Metrics Comparison  
- **Dataset:** Student performance dataset or Titanic dataset  
- **Outcome:** Tuned hyperparameters for best model performance and compared classifiers to select the optimal one.  
- **Notebook:** `Day35_HyperparameterTuning_ClassifierComparison.ipynb`

---

## ðŸ“Š Key Skills Learned
- Logistic Regression modeling for binary classification  
- Decision Trees and Random Forests for ensemble learning  
- K-Nearest Neighbors and Support Vector Machine classification  
- Hyperparameter tuning (GridSearch & RandomizedSearch)  
- Model evaluation metrics: Accuracy, Precision, Recall, F1 Score, ROC Curve  

---

